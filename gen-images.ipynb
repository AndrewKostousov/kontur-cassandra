{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "benchmarks_data_dir = 'TimeSeries\\\\Benchmarks\\\\bin\\\\Debug\\\\Raw data'\n",
    "results_dir = 'TimeSeries\\\\Benchmarks\\\\bin\\\\Debug\\\\Results\\\\Images\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "fixtures = os.listdir(benchmarks_data_dir)\n",
    "\n",
    "print(\"Found fixtures:\\n\" if fixtures else \"No fixtures were found\")\n",
    "\n",
    "for index, fixture in enumerate(fixtures):\n",
    "    print(\"{}). {}\".format(index, fixture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "# see: http://stackoverflow.com/questions/3232701/using-json-to-serialize-deserialize-timespan\n",
    "timespan_pattern = re.compile(\n",
    "r\"\"\"\n",
    "    ^[-]?                             # indicates negative timespan \n",
    "    P                                 # must be the first characted\n",
    "    (D(?P<days>\\d+))?                 # optional days part starting with T, integer\n",
    "    (T                                # optional time part starting with T\n",
    "        ((?P<hours>\\d+)H)?            # optional hours, integer format\n",
    "        ((?P<minutes>\\d+)M)?          # optional minutes, integer format\n",
    "        ((?P<seconds>\\d+(\\.\\d+)?)S)?  # optional seconds, floating point number\n",
    "    )?$\n",
    "\"\"\", re.X)\n",
    "\n",
    "\n",
    "# sample string, that should match this pattern: \"/Date(123)/\"\n",
    "datetimeoffset_pattern = re.compile(\n",
    "r\"\"\"\n",
    "    /Date\\(\n",
    "        (?P<ticks>\\d+)\n",
    "    \\)/\n",
    "\"\"\", re.X)\n",
    "\n",
    "\n",
    "timespan_types = {\n",
    "    'days': int,\n",
    "    'hours': int,\n",
    "    'minutes': int,\n",
    "    'seconds': float,\n",
    "}\n",
    "\n",
    "\n",
    "assert timespan_pattern.match(\"PT0.25S\").groupdict()['seconds'] == \"0.25\"\n",
    "assert datetimeoffset_pattern.match(r\"/Date(123)/\").groupdict()['ticks'] == \"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class Payload(object):\n",
    "    def __init__(self, data):\n",
    "        assert isinstance(data, dict)\n",
    "        self.__dict__ = {k: self.build_object(v) for k, v in data.items()}\n",
    "        \n",
    "    def build_object(self, data):\n",
    "        if isinstance(data, dict):\n",
    "            return Payload(data)\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            return [self.build_object(x) for x in data]\n",
    "        \n",
    "        if isinstance(data, str):\n",
    "            return self.parse_time(data)\n",
    "            \n",
    "        return data\n",
    "\n",
    "    def parse_time(self, data):\n",
    "        timespan_match = timespan_pattern.match(data)\n",
    "        if timespan_match:\n",
    "            groupdict = timespan_match.groupdict()\n",
    "            kwargs = {k: timespan_types[k](v) for k, v in timespan_match.groupdict().items() if v}\n",
    "            return timedelta(**kwargs).total_seconds() * 1000\n",
    "        datetimeoffset_match = datetimeoffset_pattern.match(data)\n",
    "        if datetimeoffset_match:\n",
    "            ticks = int(datetimeoffset_match.groupdict()['ticks'])\n",
    "            return timedelta(microseconds=ticks).total_seconds() * 1000\n",
    "        return data\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{\\n\\t\" + \"\\n\\t\".join(\"{} {};\".format(type(v).__name__, k) for k, v in self.__dict__.items()) + \"\\n}\"\n",
    "    \n",
    "    def describe(self):\n",
    "        print(str(self))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Payload\\n\" + str(self)\n",
    "    \n",
    "        \n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return Payload(json.load(f))\n",
    "\n",
    "\n",
    "def load(fixture):\n",
    "    fixture_dir = os.path.join(benchmarks_data_dir, fixture)\n",
    "    \n",
    "    get_filename = lambda x: os.path.splitext(x)[0]\n",
    "    load_data = lambda x: load_json(os.path.join(fixture_dir, x))\n",
    "    \n",
    "    return {\n",
    "        get_filename(benchmark): load_data(benchmark)\n",
    "        for benchmark in os.listdir(fixture_dir)\n",
    "    }\n",
    "\n",
    "def load_fixtures(fixtures):\n",
    "    fixtures = {\n",
    "        fixture: load(fixture) for fixture in fixtures\n",
    "    }\n",
    "\n",
    "    benchmarks = {}\n",
    "\n",
    "    for fixture in fixtures.keys():\n",
    "        for benchmark, data in fixtures[fixture].items():\n",
    "            if benchmark in benchmarks:\n",
    "                benchmarks[benchmark][fixture] = data\n",
    "            else:\n",
    "                benchmarks[benchmark] = {fixture: data}\n",
    "\n",
    "    return benchmarks\n",
    "\n",
    "\n",
    "benchmarks = load_fixtures(fixtures)\n",
    "print(\"Load OK\")\n",
    "\n",
    "del fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBenchmarks:\\n\")\n",
    "\n",
    "for benchmark in benchmarks:\n",
    "    print(benchmark)\n",
    "    \n",
    "print(\"\\nFixtures:\\n\")\n",
    "\n",
    "benchmark = next(iter(benchmarks))\n",
    "\n",
    "for fixture in benchmarks[benchmark]:\n",
    "    print(fixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks[\"1 reader, 4 writers\"][\"SimpleTimeSeries\"].Writers.describe()\n",
    "benchmarks[\"1 reader, 4 writers\"][\"SimpleTimeSeries\"].Writers.Measurements[0][0].describe()\n",
    "benchmarks[\"1 reader, 4 writers\"][\"SimpleTimeSeries\"].Writers.Measurements[0][0].Start.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_figure(xlabel, ylabel):\n",
    "\n",
    "    figure, ax = plt.subplots(1, 1)\n",
    "\n",
    "    figure.set_figheight(8)\n",
    "    figure.set_figwidth(15)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    return figure, ax\n",
    "\n",
    "\n",
    "def normalize(time_sequence):\n",
    "    t0 = time_sequence[0]\n",
    "    return [t - t0 for t in time_sequence]\n",
    "\n",
    "\n",
    "latency_results_dir = path.join(results_dir, 'Writers Latency')\n",
    "\n",
    "\n",
    "for benchmark_name, benchmark in benchmarks.items():\n",
    "    figure, ax = get_figure('Time', 'Writers Latency')        \n",
    "    benchmark_results_dir = path.join(latency_results_dir, benchmark_name)\n",
    "    \n",
    "    if not os.path.isdir(benchmark_results_dir):\n",
    "        os.makedirs(benchmark_results_dir)\n",
    "    \n",
    "    for index, (fixture_name, data) in enumerate(benchmark.items()):    \n",
    "        \n",
    "        all_workers_latency = []\n",
    "\n",
    "        for worker_index, worker in enumerate(data.Writers.Measurements):\n",
    "            time = normalize([x.Start.DateTime for x in worker])\n",
    "            worker_latency = [x.Latency for x in worker]\n",
    "\n",
    "            all_workers_latency += worker_latency\n",
    "\n",
    "            label = fixture_name if worker_index == 0 else ''\n",
    "            ax.plot(time, worker_latency, 'C{}'.format(index), label=label)\n",
    "\n",
    "        fixture_figure, fixture_ax = get_figure('Writers Latency', 'Operations Count')\n",
    "\n",
    "        fixture_ax.hist(all_workers_latency, 50, color='C{}'.format(index))\n",
    "        fixture_ax.legend([fixture_name])\n",
    "        \n",
    "        fixture_figure.savefig(path.join(benchmark_results_dir, fixture_name + '.png'))\n",
    "\n",
    "    ax.legend()\n",
    "    figure.savefig(path.join(benchmark_results_dir, 'Writers Latency.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_results_dir = path.join(results_dir, 'Readers Latency')\n",
    "\n",
    "\n",
    "for benchmark_name, benchmark in benchmarks.items():\n",
    "    \n",
    "    data = next(iter(benchmark.values())).Readers.Measurements\n",
    "    if len(data) == 0: \n",
    "        continue\n",
    "    \n",
    "    figure, ax = get_figure('Time', 'Readers Latency')        \n",
    "    benchmark_results_dir = path.join(latency_results_dir, benchmark_name)\n",
    "    \n",
    "    if not os.path.isdir(benchmark_results_dir):\n",
    "        os.makedirs(benchmark_results_dir)\n",
    "    \n",
    "    for index, (fixture_name, data) in enumerate(benchmark.items()):    \n",
    "\n",
    "        all_workers_latency = []\n",
    "\n",
    "        for worker_index, worker in enumerate(data.Readers.Measurements):\n",
    "            time = normalize([x.Start.DateTime for x in worker])\n",
    "            worker_latency = [x.Latency for x in worker]\n",
    "\n",
    "            all_workers_latency += worker_latency\n",
    "\n",
    "            label = fixture_name if worker_index == 0 else ''\n",
    "            ax.plot(time, worker_latency, 'C{}'.format(index), label=label)\n",
    "\n",
    "        fixture_figure, fixture_ax = get_figure('Readers Latency', 'Operations Count')\n",
    "\n",
    "        fixture_ax.hist(all_workers_latency, 50, color='C{}'.format(index))\n",
    "        fixture_ax.legend([fixture_name])\n",
    "        \n",
    "        fixture_figure.savefig(path.join(benchmark_results_dir, fixture_name + '.png'))\n",
    "\n",
    "    ax.legend()\n",
    "    figure.savefig(path.join(benchmark_results_dir, 'Readers Latency.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for benchmark_name, benchmark in benchmarks.items():\n",
    "\n",
    "    figure, ax = create_figure('Time', 'Writers Throughput')\n",
    "\n",
    "    for index, (fixture_name, fixture) in enumerate(benchmark.items()):\n",
    "        \n",
    "        for worker_index, worker in enumerate(fixture.Writers.Measurements):\n",
    "\n",
    "            time = []\n",
    "            throughput = []\n",
    "            \n",
    "            start = worker[0].Start.DateTime\n",
    "            global_start = start\n",
    "            step = 0.05\n",
    "            counter = 0\n",
    "\n",
    "            for measurement in worker:\n",
    "                if measurement.Start.DateTime > start + step:\n",
    "                    time.append(start - global_start)\n",
    "                    throughput.append(counter)\n",
    "\n",
    "                    start = measurement.Start.DateTime\n",
    "                    counter = 0\n",
    "\n",
    "                counter += measurement.Throughput\n",
    "\n",
    "            label = fixture_name if worker_index == 0 else \"\"\n",
    "            ax.plot(time, throughput, \"C{}\".format(index), label=label)\n",
    "\n",
    "    ax.legend()\n",
    "    benchmark_results_dir = path.join(results_dir, 'Writers Throughput')\n",
    "    \n",
    "    if not path.isdir(benchmark_results_dir):\n",
    "        os.makedirs(benchmark_results_dir)\n",
    "    \n",
    "    figure.savefig(path.join(benchmark_results_dir, benchmark_name + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latency_results_dir = path.join(results_dir, 'End To End Latency')\n",
    "\n",
    "\n",
    "for benchmark_name, benchmark in benchmarks.items():\n",
    "    \n",
    "    data = next(iter(benchmark.values())).Readers.WriteToReadLatency\n",
    "    if len(data) == 0: \n",
    "        continue\n",
    "    \n",
    "    figure, ax = create_figure('Operations', 'End To End Latency')\n",
    "    \n",
    "    benchmark_results_dir = path.join(latency_results_dir, benchmark_name)\n",
    "    \n",
    "    if not os.path.isdir(benchmark_results_dir):\n",
    "        os.makedirs(benchmark_results_dir)\n",
    "    \n",
    "    for index, (fixture_name, fixture) in enumerate(benchmark.items()):\n",
    "\n",
    "        latency = fixture.Readers.WriteToReadLatency[0]\n",
    "\n",
    "        figure, axs = plt.subplots(2, 1)\n",
    "\n",
    "        figure.set_figheight(10)\n",
    "        figure.set_figwidth(15)\n",
    "\n",
    "        axs[0].plot(latency, color=\"C{}\".format(index))\n",
    "        axs[0].legend([fixture_name])\n",
    "        axs[0].set_xlabel(\"Operation\")\n",
    "        axs[0].set_ylabel(\"End to End Latency\")\n",
    "\n",
    "        axs[1].hist(latency, 50, color=\"C{}\".format(index))\n",
    "        axs[1].legend([fixture_name])\n",
    "        axs[1].set_xlabel(\"End to End Latency\")\n",
    "        axs[1].set_ylabel(\"Operations Count\")\n",
    "        \n",
    "        figure.savefig(path.join(benchmark_results_dir, fixture_name + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_benchmarks = [(name, data) for name, data in benchmarks.items()]\n",
    "sorted_benchmarks = [b for b in sorted_benchmarks if next(iter(b[1].values())).Readers.WorkersCount == 1]\n",
    "sorted_benchmarks = sorted(sorted_benchmarks, key=lambda x: next(iter(x[1].values())).Writers.WorkersCount)\n",
    "\n",
    "lfigure, lax = create_figure(\"Writers Count\", \"Average Writers Latency\")\n",
    "rfigure, rax = create_figure(\"Writers Count\", \"Average Readers Latency\")\n",
    "tfigure, tax = create_figure(\"Writers Count\", \"Average Writers Throughput\")\n",
    "efigure, eax = create_figure(\"Writers Count\", \"Average End To End Latency\")\n",
    "\n",
    "writers_count = dict()\n",
    "average_latency = dict()\n",
    "average_rlatency = dict()\n",
    "average_throughput = dict()\n",
    "average_ete = dict()\n",
    "\n",
    "for benchmark_name, benchmark in sorted_benchmarks:\n",
    "    for index, (fixture_name, fixture) in enumerate(benchmark.items()):\n",
    "        if fixture_name in writers_count:\n",
    "            writers_count[fixture_name].append(fixture.Writers.WorkersCount)\n",
    "            average_latency[fixture_name].append(fixture.Writers.AverageLatency)\n",
    "            average_throughput[fixture_name].append(fixture.Writers.AverageThroughput)\n",
    "            average_ete[fixture_name].append(fixture.Readers.AverageEndToEndLatency)\n",
    "            average_rlatency[fixture_name].append(fixture.Readers.AverageLatency)\n",
    "        else:\n",
    "            writers_count[fixture_name] = [fixture.Writers.WorkersCount]\n",
    "            average_latency[fixture_name] = [fixture.Writers.AverageLatency]\n",
    "            average_throughput[fixture_name] = [fixture.Writers.AverageThroughput]\n",
    "            average_ete[fixture_name] = [fixture.Readers.AverageEndToEndLatency]\n",
    "            average_rlatency[fixture_name] = [fixture.Readers.AverageLatency]\n",
    "\n",
    "            \n",
    "for index, fixture_name in enumerate(next(iter(benchmarks.values()))):\n",
    "    lax.plot(writers_count[fixture_name], average_latency[fixture_name], \"C{}\".format(index), label=fixture_name)\n",
    "    tax.plot(writers_count[fixture_name], average_throughput[fixture_name], \"C{}\".format(index), label=fixture_name)\n",
    "    eax.plot(writers_count[fixture_name], average_ete[fixture_name], \"C{}\".format(index), label=fixture_name)\n",
    "    rax.plot(writers_count[fixture_name], average_rlatency[fixture_name], \"C{}\".format(index), label=fixture_name)\n",
    "\n",
    "lax.legend()\n",
    "tax.legend()\n",
    "eax.legend()\n",
    "rax.legend()\n",
    "\n",
    "lfigure.savefig(path.join(results_dir, 'Writers Count - Writers Latency.png'))\n",
    "tfigure.savefig(path.join(results_dir, 'Writers Count - Writers Throughput.png'))\n",
    "efigure.savefig(path.join(results_dir, 'Writers Count - End To End Latency.png'))\n",
    "rfigure.savefig(path.join(results_dir, 'Writers Count - Readers Latency.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
